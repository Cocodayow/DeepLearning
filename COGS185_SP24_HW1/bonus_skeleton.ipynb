{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 Skeleton Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-19T08:13:57.455868Z",
     "start_time": "2018-02-19T08:13:57.434706Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import re\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "import scipy.io as sio\n",
    "plt.rcParams['figure.figsize'] = 10,10\n",
    "\n",
    "import sklearn.datasets\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_iris_data.data.shape: (150, 4)\n",
      "labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "my_iris_data = sklearn.datasets.load_iris()\n",
    "print (\"my_iris_data.data.shape:\",my_iris_data.data.shape)\n",
    "print (\"labels:\",my_iris_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-19T08:13:58.418914Z",
     "start_time": "2018-02-19T08:13:58.410253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (120, 5)\n",
      "y_train.shape: (120,)\n",
      "X_test.shape: (30, 5)\n",
      "y_test.shape: (30,)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.concatenate((my_iris_data.data[10:50,:],my_iris_data.data[60:100,:], my_iris_data.data[110:150,:]))\n",
    "X_train = np.concatenate((np.ones((X_train.shape[0],1)),X_train),axis=1) # Append bias term 1\n",
    "y_train = np.concatenate((my_iris_data.target[10:50],my_iris_data.target[60:100], my_iris_data.target[110:150]))\n",
    "print (\"X_train.shape:\", X_train.shape)\n",
    "print (\"y_train.shape:\", y_train.shape)\n",
    "\n",
    "X_test = np.concatenate((my_iris_data.data[40:50,:],my_iris_data.data[90:100,:], my_iris_data.data[140:150,:]))\n",
    "X_test = np.concatenate((np.ones((X_test.shape[0],1)),X_test),axis=1) # Append bias term 1\n",
    "y_test = np.concatenate((my_iris_data.target[40:50],my_iris_data.target[90:100], my_iris_data.target[140:150]))\n",
    "print (\"X_test.shape:\", X_test.shape)\n",
    "print (\"y_test.shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the labels to get 3 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1 = np.copy(y_train); y_test1 = np.copy(y_test)\n",
    "y_train2 = np.copy(y_train); y_test2 = np.copy(y_test)\n",
    "y_train3 = np.copy(y_train); y_test3 = np.copy(y_test)\n",
    "\n",
    "y_train1[y_train == 1] = -1\n",
    "y_train1[y_train == 2] = -1\n",
    "y_train1[y_train == 0] = 1\n",
    "y_test1[y_test == 1] = -1\n",
    "y_test1[y_test == 2] = -1\n",
    "y_test1[y_test == 0] = 1\n",
    "\n",
    "y_train2[y_train == 1] = 1\n",
    "y_train2[y_train == 2] = -1\n",
    "y_train2[y_train == 0] = -1\n",
    "y_test2[y_test == 1] = 1\n",
    "y_test2[y_test == 2] = -1\n",
    "y_test2[y_test == 0] = -1\n",
    "\n",
    "y_train3[y_train == 1] = -1\n",
    "y_train3[y_train == 2] = 1\n",
    "y_train3[y_train == 0] = -1\n",
    "y_test3[y_test == 1] = -1\n",
    "y_test3[y_test == 2] = 1\n",
    "y_test3[y_test == 0] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3a: Off-the-shelf Libraries for OvA and Explicit for Multiclass on iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a.1 OvA on iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=3\n",
    "\n",
    "rf_1 = RandomForestClassifier(n_estimators=100, max_depth=12)\n",
    "bds_real1 = rf_1.fit(X_train, y_train1)\n",
    "\n",
    "rf_2 = RandomForestClassifier(n_estimators=100, max_depth=12)\n",
    "bds_real2 = rf_2.fit(X_train, y_train2)\n",
    "\n",
    "rf_3 = RandomForestClassifier(n_estimators=100, max_depth=12)\n",
    "bds_real3 = rf_3.fit(X_train, y_train3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train accuracy1: 100.0 %.\n",
      "The train accuracy2: 100.0 %.\n",
      "The train accuracy3: 100.0 %.\n"
     ]
    }
   ],
   "source": [
    "accuracy1 = bds_real1.score(X_train, y_train1)\n",
    "accuracy2 = bds_real2.score(X_train, y_train2)\n",
    "accuracy3 = bds_real3.score(X_train, y_train3)\n",
    "\n",
    "print (\"The train accuracy1:\", accuracy1*100, \"%.\")\n",
    "print (\"The train accuracy2:\", accuracy2*100, \"%.\")\n",
    "print (\"The train accuracy3:\", accuracy3*100, \"%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train accuracy: 100.0 %.\n"
     ]
    }
   ],
   "source": [
    "preds = np.array([bds_real1.predict(X_train), bds_real2.predict(X_train), bds_real3.predict(X_train)]).T\n",
    "pred = np.argmax(preds, axis=1)\n",
    "print (\"The train accuracy:\", accuracy_score(pred, y_train)*100, \"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy: 100.0 %.\n"
     ]
    }
   ],
   "source": [
    "preds = np.array([bds_real1.predict(X_test), bds_real2.predict(X_test), bds_real3.predict(X_test)]).T\n",
    "pred = np.argmax(preds, axis=1)\n",
    "print (\"The test accuracy:\", accuracy_score(pred, y_test)*100, \"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a.2 Explicit Multiclass on iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "K=10\n",
    "rf_real = RandomForestClassifier(n_estimators=100, max_depth=12)\n",
    "bds_real = rf_real.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy: 100.0 %.\n"
     ]
    }
   ],
   "source": [
    "print (\"The training accuracy:\", bds_real.score(X_train, y_train)*100, \"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy: 100.0 %.\n"
     ]
    }
   ],
   "source": [
    "print (\"The test accuracy:\",  bds_real.score(X_test, y_test)*100, \"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3b: Off-the-shelf Libraris for OvA and Explicit for Multiclass on DNA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNA dataset processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dna(filename, n_examples, n_features):\n",
    "    with open(filename) as F:\n",
    "        labels = np.zeros(n_examples)\n",
    "        data = np.zeros([n_examples, n_features])\n",
    "\n",
    "        for i, str_line in enumerate(F.readlines()):\n",
    "            line0 = list(map(int, filter(None, re.split(r'\\s|:1', str_line.strip()))))  #convert into list\n",
    "            labels[i] = line0.pop(0) - 1\n",
    "\n",
    "            for j in line0:\n",
    "                data[i][j-1] += 1.0\n",
    "        return labels, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_DNA.shape: (2000, 180)\n",
      "y_train_DNA.shape: (2000,)\n",
      "X_test_DNA.shape: (1186, 180)\n",
      "y_test_DNA.shape: (1186,)\n"
     ]
    }
   ],
   "source": [
    "y_train_DNA, X_train_DNA = read_dna(\"dna.scale.txt\",2000,180)\n",
    "y_test_DNA, X_test_DNA = read_dna(\"dna.scale.t\",1186,180)\n",
    "\n",
    "print (\"X_train_DNA.shape:\", X_train_DNA.shape)\n",
    "print (\"y_train_DNA.shape:\", y_train_DNA.shape)\n",
    "print (\"X_test_DNA.shape:\", X_test_DNA.shape)\n",
    "print (\"y_test_DNA.shape:\", y_test_DNA.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the labels to get 3 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1_DNA = np.copy(y_train_DNA); y_test1_DNA = np.copy(y_test_DNA)\n",
    "y_train2_DNA = np.copy(y_train_DNA); y_test2_DNA = np.copy(y_test_DNA)\n",
    "y_train3_DNA = np.copy(y_train_DNA); y_test3_DNA = np.copy(y_test_DNA)\n",
    "\n",
    "y_train1_DNA[y_train_DNA == 1] = -1\n",
    "y_train1_DNA[y_train_DNA == 2] = -1\n",
    "y_train1_DNA[y_train_DNA == 0] = 1\n",
    "y_test1_DNA[y_test_DNA == 1] = -1\n",
    "y_test1_DNA[y_test_DNA == 2] = -1\n",
    "y_test1_DNA[y_test_DNA == 0] = 1\n",
    "\n",
    "y_train2_DNA[y_train_DNA == 1] = 1\n",
    "y_train2_DNA[y_train_DNA == 2] = -1\n",
    "y_train2_DNA[y_train_DNA == 0] = -1\n",
    "y_test2_DNA[y_test_DNA == 1] = 1\n",
    "y_test2_DNA[y_test_DNA == 2] = -1\n",
    "y_test2_DNA[y_test_DNA == 0] = -1\n",
    "\n",
    "y_train3_DNA[y_train_DNA == 1] = -1\n",
    "y_train3_DNA[y_train_DNA == 2] = 1\n",
    "y_train3_DNA[y_train_DNA == 0] = -1\n",
    "y_test3_DNA[y_test_DNA == 1] = -1\n",
    "y_test3_DNA[y_test_DNA == 2] = 1\n",
    "y_test3_DNA[y_test_DNA == 0] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b.1 OvA  on DNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=100\n",
    "\n",
    "rf_1 = RandomForestClassifier(n_estimators=100, max_depth=15)\n",
    "bdt_real1 = rf_1.fit(X_train_DNA, y_train1_DNA)\n",
    "\n",
    "rf_2 = RandomForestClassifier(n_estimators=100, max_depth=15)\n",
    "bdt_real2 = rf_2.fit(X_train_DNA, y_train2_DNA)\n",
    "\n",
    "rf_3 = RandomForestClassifier(n_estimators=100, max_depth=15)\n",
    "bdt_real3 = rf_3.fit(X_train_DNA, y_train3_DNA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train accuracy1: 100.0 %.\n",
      "The train accuracy2: 100.0 %.\n",
      "The train accuracy3: 100.0 %.\n"
     ]
    }
   ],
   "source": [
    "accuracy1 = bdt_real1.score(X_train_DNA, y_train1_DNA)\n",
    "accuracy2 = bdt_real2.score(X_train_DNA, y_train2_DNA)\n",
    "accuracy3 = bdt_real3.score(X_train_DNA, y_train3_DNA)\n",
    "\n",
    "print (\"The train accuracy1:\", accuracy1*100, \"%.\")\n",
    "print (\"The train accuracy2:\", accuracy2*100, \"%.\")\n",
    "print (\"The train accuracy3:\", accuracy3*100, \"%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy: 100.0 %.\n"
     ]
    }
   ],
   "source": [
    "preds = np.array([bdt_real1.predict(X_train_DNA), bdt_real2.predict(X_train_DNA), bdt_real3.predict(X_train_DNA)]).T\n",
    "pred = np.argmax(preds, axis=1)\n",
    "print (\"The training accuracy:\", accuracy_score(pred, y_train_DNA)*100, \"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy: 93.00168634064082 %.\n"
     ]
    }
   ],
   "source": [
    "preds = np.array([bdt_real1.predict(X_test_DNA), bdt_real2.predict(X_test_DNA), bdt_real3.predict(X_test_DNA)]).T\n",
    "pred = np.argmax(preds, axis=1)\n",
    "print (\"The test accuracy:\", accuracy_score(pred, y_test_DNA)*100, \"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b.2 Explicit MultiClass on DNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 100\n",
    "rf_real = RandomForestClassifier(n_estimators=100, max_depth=12)\n",
    "bdt_real = rf_real.fit(X_train_DNA, y_train_DNA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy: 99.9 %.\n"
     ]
    }
   ],
   "source": [
    "print (\"The training accuracy:\", bdt_real.score(X_train_DNA, y_train_DNA)*100, \"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy: 94.35075885328837 %.\n"
     ]
    }
   ],
   "source": [
    "print (\"The test accuracy:\", bdt_real.score(X_test_DNA, y_test_DNA)*100, \"%.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "84px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
